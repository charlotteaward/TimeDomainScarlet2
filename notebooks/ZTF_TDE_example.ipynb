{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55f41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cw1074/HSC/pulsars/scarlet/scarlet/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cw1074/.conda/envs/scarlet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cw1074/scarletmultisource/scarlet2/scarlet2/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import corner\n",
    "import scarlet\n",
    "print(scarlet.__file__)\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from numpyro.distributions import constraints\n",
    "from scarlet.display import AsinhMapping,AsinhPercentileNorm,show_scarlet2_scene,LinearPercentileNorm\n",
    "import glob\n",
    "import sep\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from astropy.wcs import WCS\n",
    "from scarlet.source import StaticSource,MultiExtendedSource, StaticMultiExtendedSource\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from jax import random, jit\n",
    "import distrax\n",
    "import optax\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpyro.distributions as dist\n",
    "from scarlet2 import *\n",
    "import scarlet2\n",
    "from scarlet2 import relative_step\n",
    "from functools import partial\n",
    "print(scarlet2.__file__)\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gray', interpolation='none', origin='lower')\n",
    "import astrophot as ap\n",
    "pixelscale=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80c0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plot_style(doit=True,serif=True,use_tex=True):\n",
    "    # NB -- for this to work\n",
    "    # sudo apt install texlive-latex-base\n",
    "    # sudo apt install msttcorefonts -qq\n",
    "    # sudo apt-get install dvipng texlive-latex-extra texlive-fonts-recommended cm-super\n",
    "    # rm ~/.cache/matplotlib -rf\n",
    "    from matplotlib import cycler\n",
    "    new_rcparams = {\n",
    "        # Set color cycle: blue, green, yellow, red, violet, gray\n",
    "        #'#axes.prop_cycle' : cycler('color', ['0C5DA5', '00B945', 'FF9500', 'FF2C00', '845B97', '474747', '9e9e9e']),\n",
    "        # Set color cycle: blue, orange, green, red, violet, gray\n",
    "        'axes.prop_cycle' : cycler('color', ['0C5DA5', 'FF9500', '00B945', 'FF2C00', '845B97', '474747', '9e9e9e']),\n",
    "        # Set default figure size\n",
    "        'figure.figsize' : (4*1.5, 3*1.5),\n",
    "        # Set x axis\n",
    "        'xtick.direction' : 'in',\n",
    "        'xtick.major.width' : 0.5,\n",
    "        'xtick.minor.size' : 1.5*2,\n",
    "        'xtick.minor.width' : 0.5,\n",
    "        'xtick.minor.visible' : True,\n",
    "        'xtick.top' : True,\n",
    "        # Set y axis\n",
    "        'ytick.direction' : 'in',\n",
    "        'ytick.major.size' : 3*2,\n",
    "        'ytick.major.width' : 0.5,\n",
    "        'ytick.minor.size' : 1.5*2,\n",
    "        'ytick.minor.width' : 0.5,\n",
    "        'ytick.minor.visible' : True,\n",
    "        'ytick.right' : True,\n",
    "        # Set line widths\n",
    "        'axes.linewidth' : 0.5,\n",
    "        'grid.linewidth' : 0.5,\n",
    "        'lines.linewidth' : 1.,\n",
    "        # Remove legend' frame\n",
    "        'legend.frameon' : False,\n",
    "        # Always save as 'tight'\n",
    "        'savefig.bbox' : 'tight',\n",
    "        'savefig.pad_inches' : 0.05,\n",
    "    }\n",
    "    if use_tex:\n",
    "        new_rcparams.update({\n",
    "            # Use LaTeX for math formatting\n",
    "            'text.usetex' : True,\n",
    "            'text.latex.preamble' : r'\\usepackage{amsmath}'\n",
    "            })\n",
    "    if serif:\n",
    "        new_rcparams.update({\n",
    "            # Use serif fonts\n",
    "            'font.serif' : 'Times New Roman',\n",
    "            'font.family' : 'serif',\n",
    "            'mathtext.fontset' : 'dejavuserif',\n",
    "            'legend.fontsize' : 'large',\n",
    "            'xtick.labelsize' : 'x-large',\n",
    "            'ytick.labelsize' : 'x-large',\n",
    "            'axes.labelsize' : 'xx-large',\n",
    "            })\n",
    "    if doit:\n",
    "        plt.rcParams.update(new_rcparams)\n",
    "    else:\n",
    "        return new_rcparams\n",
    "set_plot_style()\n",
    "plt.rcParams[\"font.family\"] = \"Serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6de60e",
   "metadata": {},
   "source": [
    "Provide name and position of source, desired bands, and location of image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1047290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandall=['g','i','r']\n",
    "coords = np.loadtxt('/home/cw1074/ZTF/TDEpos.txt',dtype=str,skiprows=0)\n",
    "srcs = coords[:,0]\n",
    "ras = coords[:,1]\n",
    "decs = coords[:,2]\n",
    "mjdstarts = coords[:,3]\n",
    "\n",
    "#Model the 2nd TDE in the list\n",
    "srcname = srcs[1]\n",
    "ra = float(ras[1])\n",
    "dec = float(decs[1])\n",
    "mjdstart = float(mjdstarts[1])-2400000.5\n",
    "\n",
    "coord_transient = SkyCoord(ra*u.deg, dec*u.deg, frame='icrs')\n",
    "\n",
    "imagedir = '/scratch/gpfs/cw1074/ZTFimages/'+srcname\n",
    "plotdir = '/scratch/gpfs/cw1074/ZTFimages/'+srcname+'/plots'\n",
    "if not os.path.exists(plotdir):\n",
    "    os.mkdir(plotdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd99ff",
   "metadata": {},
   "source": [
    "Define a function which stacks the images and performs source detection on the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fce9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCatalog(observations, lvl=3, wave=True):\n",
    "    normed_images = np.asarray([obs.data for obs in observations])\n",
    "    interps = [scarlet.interpolation.interpolate_observation(obs, observations[0]) for obs in obssingle]\n",
    "    interps = np.asarray(interps/np.sum(interps))\n",
    "    detect_image = np.sum(interps,axis=(0,1))\n",
    "    # Wavelet transform\n",
    "    wave_detect = scarlet.Starlet.from_image(detect_image).coefficients\n",
    "\n",
    "    if wave:\n",
    "        # Creates detection from the first 3 wavelet levels\n",
    "        detect = wave_detect[:lvl,:,:].sum(axis = 0)\n",
    "    else:\n",
    "        detect = detect_image\n",
    "\n",
    "        # Runs SEP detection\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect-bkg.globalback, 5, err=bkg.globalrms)\n",
    "    background=[]\n",
    "    bg_rms=[]\n",
    "    for obs in observations:\n",
    "        img = obs.data\n",
    "        if np.size(img.shape) == 3:\n",
    "            bg_rms.append(np.array([sep.Background(band).globalrms for band in img]))\n",
    "            background.append(np.array([sep.Background(band).globalback for band in img]))\n",
    "        else:\n",
    "            bg_rms.append(sep.Background(img).globalrms)\n",
    "            background.append(sep.Background(img).globalback)\n",
    "    return catalog, bg_rms, detect_image, background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a39ff1",
   "metadata": {},
   "source": [
    "For each band, obtain the science, weight and PSF images. Loop over each image and create scarlet1 and scarlet2 observation objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37cbfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m orig \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresamp.cutout.fits\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.fits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     orig_hdu \u001b[38;5;241m=\u001b[39m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m       \n",
      "File \u001b[0;32m~/.conda/envs/scarlet/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:175\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/scarlet/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:410\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\u001b[38;5;28mcls\u001b[39m, fileobj, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m              save_backup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lazy_load_hdus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m              ignore_missing_simple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/scarlet/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:1060\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m~/.conda/envs/scarlet/lib/python3.10/site-packages/astropy/io/fits/file.py:200\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(pos)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obssingle=[]\n",
    "observations_sc2_init=[]\n",
    "channels=[]\n",
    "channels_sc2 =[]\n",
    "channels_zeroed=[]\n",
    "times=[]\n",
    "zps =[]\n",
    "maglims =[]\n",
    "for band in bandall:\n",
    "    images = glob.glob(imagedir+'/ztf_*_z'+band+'*sciimg.resamp.cutout.fits')\n",
    "    \n",
    "    weights = [im.rstrip('resamp.cutout.fits')+'.resamp.weigh.cutout.fits' for im in images]\n",
    "    psfs = [im.rstrip('resamp.cutout.fits')+'daopsfcent.resamp.fits' for im in images]\n",
    "    \n",
    "    for ind,(img,weight,psf) in enumerate(zip(images,weights,psfs)):\n",
    "        #Use astropy fits to read in the image file\n",
    "        obs_hdu = fits.open(img)\n",
    "        data_ztf = obs_hdu[0].data.byteswap().newbyteorder()\n",
    "        w = WCS(obs_hdu[0].header)\n",
    "        N1, N2 = data_ztf.shape\n",
    "        data_ztf = data_ztf.reshape(1, N1, N2)\n",
    "        data_ztf[np.isnan(data_ztf)] = 0\n",
    "        #Read in the original image to get some metadata\n",
    "        orig = img.rstrip('resamp.cutout.fits')+'.fits'\n",
    "        try:\n",
    "            orig_hdu = fits.open(orig)\n",
    "        except FileNotFoundError:\n",
    "            continue       \n",
    "        maglim = orig_hdu[0].header['MAGLIM']\n",
    "\n",
    "        if orig_hdu[0].header['OBSMJD'] > mjdstart+800 or orig_hdu[0].header['OBSMJD'] < mjdstart-200:\n",
    "            continue\n",
    "\n",
    "        #Use astropy fits to read in the weight file\n",
    "        try:\n",
    "            weight_hdu = fits.open(weight)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        weight_ztf = weight_hdu[0].data.byteswap().newbyteorder()\n",
    "        \n",
    "        Nw1, Nw2 = weight_ztf.shape\n",
    "        weight_ztf = weight_ztf.reshape(1, Nw1, Nw2)\n",
    "        try:\n",
    "            weight_ztf[np.isnan(data_ztf)] = 0\n",
    "        except IndexError:\n",
    "            continue\n",
    "    \n",
    "        if np.sum(weight_ztf==0)>0.01*weight_ztf.shape[-2]*weight_ztf.shape[-1] or maglim<19.5:\n",
    "            #print('Poor image, skipping')\n",
    "            continue\n",
    "        times.append(orig_hdu[0].header['OBSMJD'])\n",
    "        zps.append(orig_hdu[0].header['MAGZP'])\n",
    "        orig_hdu.close()\n",
    "        #Create a unique channel identifier which contains information about the band and the image index\n",
    "        channel = [band+str(ind)]\n",
    "        channel_sc2 = (band, str(ind)) \n",
    "        channels.append(band+str(ind))\n",
    "        channels_sc2.append(channel_sc2)\n",
    "\n",
    "        if orig_hdu[0].header['OBSMJD']>mjdstart and orig_hdu[0].header['OBSMJD']<mjdstart+500:\n",
    "            channels_zeroed.append(channel_sc2)\n",
    "        #Read in the point spread function image and create the scarlet1 PSF object\n",
    "        psf_ztf_data = fits.open(psf)[0].data        \n",
    "        Np1, Np2 = psf_ztf_data.shape\n",
    "        psf_ztf = scarlet.ImagePSF(psf_ztf_data)\n",
    "        # Create the scarlet1 observation object and add it to our list of observations\n",
    "        obs_ztf = scarlet.Observation(data_ztf,\n",
    "            wcs=w,\n",
    "            psf=psf_ztf,\n",
    "            channels=channel,\n",
    "            weights=weight_ztf)\n",
    "        obssingle.append(obs_ztf)\n",
    "        # Create the scarlet2 observation object and add it to our list of observations\n",
    "        obs_sc2 = scarlet2.Observation(jnp.asarray(data_ztf), jnp.asarray(weight_ztf), psf=scarlet2.ArrayPSF(jnp.asarray(psf_ztf_data)),channels=[channel_sc2],wcs=w)\n",
    "        observations_sc2_init.append(obs_sc2)\n",
    "        maglims.append(maglim)\n",
    "indbest = np.argmax(maglim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17010022",
   "metadata": {},
   "source": [
    "Run source detection to create a catalog of source positions. Subtract background from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = 3\n",
    "wave = 1\n",
    "#Obtain source catalog and background flux estimation from our makeCatalog function\n",
    "catalog_single, bgsingle, detectsingle, globalback = makeCatalog(obssingle, lvl, wave)\n",
    "obssinglearr=np.asarray(obssingle)\n",
    "bgsinglearr=np.asfarray(bgsingle)\n",
    "pixel = np.stack((catalog_single['y'], catalog_single['x']), axis=1)\n",
    "ra_dec = [obs.get_sky_coord(pixel) for obs in obssinglearr]\n",
    "observations_sc2=[]\n",
    "normsingle=[]\n",
    "for ind,(obs,obs2,bg,back) in enumerate(zip(obssingle,observations_sc2_init,bgsingle,globalback)):\n",
    "    w = obs2.frame.wcs\n",
    "    obs.weights = obs2.weights\n",
    "    \n",
    "    #Subtract background flux\n",
    "    obs.data = obs.data-back\n",
    "    obs_sc2 = scarlet2.Observation(jnp.asarray(obs.data), jnp.asarray(obs.weights), psf=scarlet2.ArrayPSF(jnp.asarray(obs.psf.get_model())),channels=[channels_sc2[ind]],wcs=w)\n",
    "    observations_sc2.append(obs_sc2)\n",
    "    #Store norm based on observation data\n",
    "    normsingle.append(AsinhPercentileNorm(obs.data[:,10:-10,10:-10],percentiles=[0.01, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.asarray(ra_dec).shape==(2,):\n",
    "    separ=[0]\n",
    "    indtransient=0\n",
    "else:\n",
    "    c2 = [SkyCoord(ra*u.deg,dec*u.deg,frame='icrs') for ra,dec in ra_dec[0]]\n",
    "    separ = [coord_transient.separation(c).arcsecond for c in c2]\n",
    "    indtransient = np.argmin(separ)\n",
    "indtransientinit = np.copy(indtransient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea505e8",
   "metadata": {},
   "source": [
    "Initialize scarlet to match up images to corresponding bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.asarray([obs.channels[0][0] for obs in obssingle])\n",
    "bands0,inds0 = np.unique([obs.channels[0][0] for obs in obssingle],return_index=True)\n",
    "bands = epochs[inds0]\n",
    "bandind = [np.argwhere(bands==e)[0][0] for e in epochs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754399cb",
   "metadata": {},
   "source": [
    "Define the scarlet2 PSF model and model frame. Match the model frame to the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_psf_sc2 = scarlet2.GaussianPSF(0.9)\n",
    "model_frame_sc2 = scarlet2.Frame(scarlet2.Box((len(observations_sc2),observations_sc2[0].data.shape[-2],observations_sc2[0].data.shape[-1])), psf=frame_psf_sc2, channels=channels_sc2, wcs=w)\n",
    "for obs in observations_sc2:\n",
    "    obs.match(model_frame_sc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6390343",
   "metadata": {},
   "source": [
    "Initialize scarlet2 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7677908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from galaxygrad import ZTF_ScoreNet32\n",
    "\n",
    "stepnum=3000\n",
    "gal_step = 2e-3\n",
    "AGN_step = 2e-3\n",
    "from scarlet2 import nn\n",
    "model_size = 32\n",
    "count = 0\n",
    "prior = nn.ScorePrior(\n",
    "            model=ZTF_ScoreNet32\n",
    "        )\n",
    "ra_dec = np.asarray(ra_dec)\n",
    "morph_step = lambda p: scarlet2.relative_step(p, factor=1e-3)\n",
    "AGN_step = lambda p: scarlet2.relative_step(p, factor=5e-4)\n",
    "          \n",
    "with scarlet2.Scene(model_frame_sc2) as scene:\n",
    "    for i,pos in enumerate(ra_dec[0]):      \n",
    "        coord = SkyCoord(pos[0],pos[1],unit=\"deg\")\n",
    "        pospix = np.asfarray(observations_sc2_init[0].frame.wcs.world_to_pixel(coord))\n",
    "        center = jnp.asarray(np.asfarray([pos[0],pos[1]]))\n",
    "        centerpix = jnp.asarray([pospix[1]+1.0,pospix[0]+1.0])\n",
    "        if i==indtransient:    \n",
    "            flux = np.asarray(initialization.pixel_spectrum(observations_sc2, center))[:,0]\n",
    "            for find in range(len(flux)):\n",
    "                if channels_sc2[find] not in channels_zeroed:\n",
    "                    flux[find]=1e-20\n",
    "            flux = jnp.asarray(flux) \n",
    "            n_steps, peak_value2 = stepnum, jnp.max(flux[~np.isinf(flux)])\n",
    "\n",
    "            schedule3 = optax.cosine_onecycle_schedule(n_steps, peak_value2, final_div_factor=1)\n",
    "            AGN_step = lambda p: scarlet2.relative_step(p, factor=5e-4)\n",
    "           \n",
    "            scarlet2.PointSource(\n",
    "                    centerpix,\n",
    "                    scarlet2.TransientArraySpectrum(jnp.asarray(flux),epochs = channels_zeroed))\n",
    "            print('Making host galaxy')\n",
    "            flux = np.asarray(initialization.pixel_spectrum(observations_sc2, center))[:,0][inds0]\n",
    "            \n",
    "            try:\n",
    "                morph_init = initialization.adaptive_gaussian_morph(observations_sc2[0], center)\n",
    "                if morph_init.shape[0]>30:\n",
    "                    excess = morph_init.shape[0]-30\n",
    "                    morph_init = morph_init[excess:-excess,excess:-excess]\n",
    "                else:\n",
    "                    padsize=[int((30-morph_init.shape[0])/2),int((30-morph_init.shape[1])/2)]\n",
    "                    morph_init = np.pad(morph_init,(padsize[0], padsize[1]), 'edge') + 1e-12\n",
    "                morph_init = morph_init/np.sum(morph_init)+1e-12\n",
    "            except ValueError:\n",
    "                print('Initializing as point source')\n",
    "                morph_init = morph_init/np.sum(morph_init)+1e-12\n",
    "                if morph_init.shape[0]>30:\n",
    "                    excess = morph_init.shape[0]-30\n",
    "                    morph_init = morph_init[excess:-excess,excess:-excess]\n",
    "                else:\n",
    "                    padsize=[int((30-morph_init.shape[0])/2),int((30-morph_init.shape[1])/2)]\n",
    "                    morph_init = np.pad(observations_sc2[0].frame.psf()[0,:,:]-np.min(observations_sc2[0].frame.psf()),(padsize[0], padsize[1]), 'edge')\n",
    "                morph_init = morph_init/np.sum(morph_init)+1e-12\n",
    "        \n",
    "            morph_init = jnp.asarray(morph_init)\n",
    "\n",
    "            scarlet2.Source(\n",
    "                centerpix,\n",
    "                scarlet2.StaticArraySpectrum(jnp.asarray(flux),filters=bandall),\n",
    "                scarlet2.ArrayMorphology(morph_init))\n",
    "\n",
    "        else:\n",
    "            print('Making other galaxy')\n",
    "            flux = jnp.asarray(np.asarray(initialization.pixel_spectrum(observations_sc2, center))[:,0][inds0])\n",
    "            try:\n",
    "                morph_init = initialization.adaptive_gaussian_morph(observations_sc2[0], center)\n",
    "            except ValueError:\n",
    "                print('Initializing as point source')\n",
    "                morph_init = np.pad(observations_sc2[0].frame.psf()[0,:,:]-np.min(observations_sc2[0].frame.psf()),(5, 5), 'edge')\n",
    "            morph_init = morph_init/np.sum(morph_init)+1e-12\n",
    "            morph_init = jnp.asarray(morph_init)\n",
    "\n",
    "            scarlet2.Source(\n",
    "                centerpix,\n",
    "                scarlet2.StaticArraySpectrum(jnp.asarray(flux),filters=bandall),\n",
    "                scarlet2.ArrayMorphology(morph_init))\n",
    "pos_step = lambda p: scarlet2.relative_step(p, factor=1e-3)\n",
    "parameters = scene.make_parameters()\n",
    "for i in range(len(scene.sources)):\n",
    "    if i==indtransient:\n",
    "        parameters += Parameter(scene.sources[i].spectrum.data, name=f\"spectrum.{i}\", constraint=constraints.positive, stepsize=AGN_step)\n",
    "        parameters += Parameter(scene.sources[i].morphology.center, name=f\"spectrum.{i}\", constraint=constraints.positive, stepsize=pos_step)\n",
    " \n",
    "    else:\n",
    "        parameters += Parameter(scene.sources[i].spectrum.data, name=f\"spectrum.{i}\", constraint=constraints.positive, stepsize=gal_step)\n",
    "        parameters += Parameter(scene.sources[i].morphology.data, name=f\"morph.{i}\", constraint=constraints.positive, stepsize=morph_step)\n",
    "        \n",
    "scene.set_spectra_to_match(observations_sc2,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73896246",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(\n",
    "    scene,\n",
    "    observation=observations_sc2[indbest],#np.asarray(observations_sc2),\n",
    "    norm=normsingle[indbest],\n",
    "    channel_map=None,#np.asarray(channels_sc2[:1]),#[:1],#inds0],\n",
    "    show_model=False,\n",
    "    show_observed=True,\n",
    "    show_rendered=True,\n",
    "    show_residual=True,\n",
    "    add_labels=True,\n",
    "    add_boxes=True,\n",
    "    #figsize=None,\n",
    "    linear=True,\n",
    ")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602efa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the initalization point source and host galaxy models\n",
    "import cmasher as cmr\n",
    "cmap = cmr.lilac\n",
    "int_method='none'\n",
    "fig, axes = plt.subplots(1, len( scene.sources ), figsize=(15,6),dpi=120)\n",
    "for i, ax in enumerate(axes):\n",
    "    if i==indtransient:\n",
    "        y = scene.sources[i].morphology()\n",
    "    else:\n",
    "        y = scene.sources[i].morphology.data\n",
    "    ax.imshow(np.log(y), cmap = cmap,interpolation=int_method)#,vmin = np.max([np.min(np.log(y)[np.log(y)>-15]),-15]))\n",
    "    ax.set_title(f\"source {i}\", fontsize = 18)\n",
    "    ax.invert_yaxis()\n",
    "plt.suptitle('reconstructed sources (transient = '+str(indtransient)+')', fontsize=12)#,y=0.75)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84e70f",
   "metadata": {},
   "source": [
    "Plot scarlet2 initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db49c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_steps, peak_value = stepnum, 1\n",
    "schedule = optax.cosine_onecycle_schedule(n_steps, peak_value, final_div_factor=1)\n",
    "flux = scene.sources[indtransient].spectrum.data\n",
    "\n",
    "#Fit the scene\n",
    "scene_ = scene.fit(observations_sc2, parameters,max_iter=stepnum, e_rel=1e-6, schedule=schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921602d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observations_sc2[0].data.shape)\n",
    "scarlet2.plot.scene(\n",
    "    scene_,\n",
    "    observation=observations_sc2[0],#np.asarray(observations_sc2),\n",
    "    norm=normsingle[0],\n",
    "    channel_map=None,#np.asarray(channels_sc2[:1]),#[:1],#inds0],\n",
    "    show_model=False,\n",
    "    show_observed=True,\n",
    "    show_rendered=True,\n",
    "    show_residual=True,\n",
    "    add_labels=True,\n",
    "    add_boxes=True,\n",
    "    #figsize=None,\n",
    "    linear=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the point source and host galaxy models\n",
    "import cmasher as cmr\n",
    "cmap = cmr.lilac\n",
    "int_method='none'\n",
    "fig, axes = plt.subplots(1, len( scene.sources ), figsize=(15,6),dpi=120)\n",
    "for i, ax in enumerate(axes):\n",
    "    if i==indtransient:\n",
    "        y = scene_.sources[i].morphology()\n",
    "    else:\n",
    "        y = scene_.sources[i].morphology.data\n",
    "    ax.imshow(np.log(y), cmap = cmap,interpolation=int_method,vmin = np.max([np.min(np.log(y)[np.log(y)>-15]),-15]))\n",
    "    ax.set_title(f\"source {i}\", fontsize = 18)\n",
    "    ax.invert_yaxis()\n",
    "plt.suptitle('reconstructed sources (transient = '+str(indtransient)+')', fontsize=12)#,y=0.75)\n",
    "plt.savefig(plotdir+'/'+srcname+'_reconstructed_sources.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b61587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the point source and host galaxy models\n",
    "import cmasher as cmr\n",
    "cmap = cmr.lilac\n",
    "int_method='none'\n",
    "fig=plt.figure(figsize=(4,4))#, axes = plt.subplots(1, len( scene.sources ), figsize=(15,6),dpi=120)\n",
    "\n",
    "y = scene_.sources[indtransient+1].morphology.data\n",
    "plt.imshow(np.log(y), cmap = cmap,interpolation=int_method,vmin = np.max([np.min(np.log(y)[np.log(y)>-15]),-15]))\n",
    "\n",
    "plt.savefig(plotdir+'/'+srcname+'_reconstructed_galaxy.pdf')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9197e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indgal=indtransient+1\n",
    "zps = np.asfarray(zps)\n",
    "flux = scene_.sources[indtransient].spectrum.data * np.sum(scene_.sources[indtransient].morphology(),axis=(-2,-1)) \n",
    "fluxgal = scene_.sources[indgal].spectrum.data * np.sum(scene_.sources[indgal].morphology(),axis=(-2,-1)) \n",
    "times=np.asfarray(times)\n",
    "timesz = ['2018-01-01T00:00:00']\n",
    "t = Time(timesz, format='isot', scale='utc')\n",
    "now = t[0]\n",
    "\n",
    "for bind,(b,c,background) in enumerate(zip(['g','i','r'],['green','orange','red'],bgsinglearr)):\n",
    "    mags = zps[epochs==b]-2.5*np.log10(flux[epochs==b])\n",
    "    plt.errorbar(times[epochs==b][mags<22]-now.mjd,mags[mags<22],yerr = 1.0857*bgsinglearr[epochs==b][mags<22][:,0]*3/flux[epochs==b][mags<22],label=b,color=c,marker='.',linestyle=' ',ecolor='grey',elinewidth=0.4,capthick=0.4)\n",
    "       \n",
    "plt.xlabel('Days since 2018-01-01')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylim((22,19))\n",
    "plt.xlim((500,850))\n",
    "plt.ylabel('Scarlet Point Source Magnitude')\n",
    "plt.legend(frameon=True)\n",
    "\n",
    "\n",
    "plt.savefig(plotdir+'/'+srcname+'_lightcurve.pdf')\n",
    "print('Saved',plotdir+'/'+srcname+'_lightcurve.pdf')\n",
    "plt.xlim((mjdstart-now.mjd,mjdstart-now.mjd+300))\n",
    "plt.savefig(plotdir+'/'+srcname+'_lightcurve_zoom.pdf')\n",
    "print('Saved',plotdir+'/'+srcname+'_lightcurve_zoom.pdf')\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer.initialization import init_to_sample\n",
    "dosamplinglc=True\n",
    "    \n",
    "if dosamplinglc==True:\n",
    "    parameters = scene_.make_parameters()\n",
    "    \n",
    "    p = scene_.sources[indtransient+1].morphology.data\n",
    "    prior = dist.Normal(p, scale=1)\n",
    "    parameters += Parameter(p, name=f\"morphology.data:\"+str(indtransient+1), prior=prior)\n",
    "    p = scene_.sources[indtransient+1].spectrum.data\n",
    "    prior = dist.Normal(p, scale=1)\n",
    "    parameters += Parameter(p, name=f\"spectrum:\"+str(indtransient+1), prior=prior)\n",
    "    p = scene_.sources[indtransient].spectrum.data\n",
    "    prior = dist.Normal(p, scale=1)\n",
    "    parameters += Parameter(p, name=f\"spectrum:\"+str(indtransient), prior=prior)\n",
    "    p = scene_.sources[indtransient].morphology.center\n",
    "    prior = dist.Normal(p, scale=1)\n",
    "    parameters += Parameter(p, name=f\"morphology.center:\"+str(indtransient), prior=prior)\n",
    "    mcmc = scene_.sample(observations_sc2,parameters,num_warmup=150, num_samples=500, dense_mass=True, init_strategy=init_to_sample) \n",
    "    \n",
    "    #Get point source position and uncertainties\n",
    "    q = mcmc.get_samples()['morphology.center:'+str(indtransient)] \n",
    "    q1 = np.percentile(q,[2.5,16,50,84,97.5],axis=0) \n",
    "    centerAGN = np.asfarray([q1[2,0],q1[2,1]])\n",
    "    errorAGN = np.asarray([np.abs(q1[3,0]-q1[1,0]),np.abs(q1[3,1]-q1[1,1])])\n",
    "    \n",
    "    #Get host galaxy spectrum and uncertainties\n",
    "    q = mcmc.get_samples()['spectrum:'+str(indtransient+1)] \n",
    "    q1 = np.percentile(q,[2.5,16,50,84,97.5],axis=0)\n",
    "    fac = np.sum(scene_.sources[indtransient+1].morphology(),axis=(-2,-1))\n",
    "    galfluxes = []\n",
    "    galfluxerrors = []\n",
    "    for i,b in zip(range(q1.shape[1]),inds0):\n",
    "        print(i,'median = ',q1[2][i],'std = ',(q1[3][i]-q1[1][i])/2)\n",
    "        galfluxes.append(q1[2][i]*fac)\n",
    "        galfluxerrors.append((q1[3][i]-q1[1][i])/2*fac)\n",
    "    \n",
    "    #corner.corner(mcmc).show()\n",
    "    plt.clf()\n",
    "    sedgal = np.asfarray(galfluxes)\n",
    "    sedgalerr = np.asfarray(galfluxerrors)\n",
    "    \n",
    "    #Get transient light curve\n",
    "    q = mcmc.get_samples()['spectrum:'+str(indtransient)]\n",
    "    q1 = np.percentile(q,[2.5,16,50,84,97.5],axis=0) \n",
    "    fac = np.sum(scene_.sources[indtransient].morphology(),axis=(-2,-1)) \n",
    "    fluxes = [] \n",
    "    fluxerrors = [] \n",
    "    for i in range(q1.shape[1]): \n",
    "        print(i,'median = ',q1[2][i],'std = ',(q1[3][i]-q1[1][i])/2) \n",
    "        fluxes.append(q1[2][i]*fac) \n",
    "        fluxerrors.append((q1[3][i]-q1[1][i])/2*fac)\n",
    "\n",
    "    zps = np.asfarray(zps)\n",
    "    fluxes = np.asfarray(fluxes)\n",
    "    fluxerrors = np.asfarray(fluxerrors) \n",
    "    times=np.asfarray(times)\n",
    "    fac = np.sum(scene_.sources[indtransient].morphology(),axis=(-2,-1))\n",
    "    \n",
    "    for bind,(b,c) in enumerate(zip(bandall,['green','orange','red','purple','blue'])):\n",
    "        plt.errorbar(times[epochs==b]-57700,fluxes[epochs==b],yerr = fluxerrors[epochs==b],linestyle='',label=b,color=c,marker='.')#+fluxgal[epochs==b]),label=b,color=c,marker='.')\n",
    "    plt.xlabel('MJD-57700')\n",
    "    plt.ylabel('Flux')\n",
    "    plt.legend()\n",
    "    plt.title(srcname)\n",
    "    plt.savefig(plotdir+'/'+srcname+'_lc_flux.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    outlchead=['MJD','FLUX','FLUXERR','BAND']\n",
    "    outlc=np.column_stack((times,fluxes,fluxerrors,epochs))\n",
    "    outlc = np.vstack((outlchead,outlc))\n",
    "    np.savetxt(plotdir+'/lc.txt',np.asarray(outlc,dtype=str),fmt='%s')\n",
    "    sed=[]\n",
    "    sederr=[]\n",
    "    for b,c in zip(bandall,['green','orange','red','purple','blue']):\n",
    "        sed.append(np.mean(fluxes[epochs==b]))\n",
    "        sederr.append(np.std(fluxes[epochs==b]))\n",
    "        plt.errorbar(times[epochs==b]-57700,zps[epochs==b]-2.5*np.log10(fluxes[epochs==b]),yerr = 1.0857*fluxerrors[epochs==b]/np.abs(fluxes[epochs==b]),linestyle='',label=b,color=c,marker='.')#+fluxgal[epochs==b]),label=b,color=c,marker='.')\n",
    "    plt.xlabel('MJD-57700')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.ylim((22,19))#gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.savefig(plotdir+'/'+srcname+'_lc_mag.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855a50b",
   "metadata": {},
   "source": [
    "import gzip\n",
    "with gzip.open('/home/cw1074/ZTF/ZTF-AGN/ZTFimages/lightcurves/'+srcname+'-lc-f.dat.gz') as f:\n",
    "    content = np.loadtxt(f,skiprows=1,dtype=str)\n",
    "    #content = f.read()\n",
    "    jd = np.asfarray(content[:,0])-2400000.5 - 57700\n",
    "    bands = content[:,7]\n",
    "    mags = np.asfarray(content[:,4])\n",
    "    magerr = np.asfarray(content[:,5])\n",
    "for b,c in zip(['g','r','i'],['green','red','orange']):\n",
    "    plt.errorbar(jd[bands==b],mags[bands==b],yerr=magerr[bands==b],label=b,color=c,marker='.',linestyle=' ')\n",
    "plt.xlabel('JD-57700')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer.initialization import init_to_sample\n",
    "\n",
    "parameters = scene_.make_parameters()\n",
    "p = scene_.sources[indtransient].morphology.center\n",
    "prior = dist.Normal(p, scale=1)\n",
    "parameters += Parameter(p, name=f\"morphology.data:\"+str(indtransient+1), prior=prior)\n",
    "parameters += Parameter(p, name=f\"morphology.center:\"+str(indtransient), prior=prior)\n",
    "parameters += Parameter(p, name=f\"spectrum:\"+str(indtransient), prior=prior)\n",
    "\n",
    "mcmc = scene_.sample(observations_sc2,parameters,num_warmup=400, num_samples=1000, dense_mass=True, init_strategy=init_to_sample) \n",
    "q = mcmc.get_samples()['morphology.center:'+str(indtransient)] \n",
    "q1 = np.percentile(q,[2.5,16,50,84,97.5],axis=0) \n",
    "centerAGN = np.asfarray([q1[2,0],q1[2,1]])\n",
    "errorAGN = np.asarray([np.abs(q1[3,0]-q1[1,0]),np.abs(q1[3,1]-q1[1,1])])\n",
    "corner.corner(mcmc).show() \n",
    "plt.savefig(plotdir+'/'+srcname+'_transientcenter_corner.png')\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "observations_sc2_arr =np.asarray(observations_sc2)\n",
    "normsinglearr =np.asarray(normsingle)\n",
    "obs_subtracted=[]\n",
    "for i,(chan,obs,norm) in enumerate(zip(channels,observations_sc2_arr[:30],normsinglearr[:30])):\n",
    "    model_ = obs.render(scene_.sources[indtransient]())\n",
    "    boxslice = scene_.sources[indtransient].bbox.slices\n",
    "    newdata = copy.deepcopy(np.asarray(obs.data)) \n",
    "    newdata[boxslice] = newdata[boxslice] - model_\n",
    "    obs2 = scarlet2.Observation(jnp.asarray(newdata), jnp.asarray(obs.weights), psf=scarlet2.ArrayPSF(jnp.asarray(obs.frame.psf())),channels=obs.frame.channels)\n",
    "    obs2.match(model_frame_sc2)\n",
    "    obs_subtracted.append(obs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract all rendered models except the host galaxy from the images so they can be stacked\n",
    "obs_subtracted=[]\n",
    "for i,(chan,obs) in enumerate(zip(channels_sc2,observations_sc2_arr)):\n",
    "    newdata = copy.deepcopy(np.asarray(obs.data)) \n",
    "    for isource,src in enumerate(scene_.sources):\n",
    "        if isource==indtransient+1:\n",
    "            continue\n",
    "        model_ = obs.render(scene_.sources[isource]())\n",
    "        boxslice = scene_.sources[isource].bbox.slices\n",
    "        overlap1,overlap2 = bbox.overlap_slices(scene_.sources[indtransient].bbox, scene_.sources[isource].bbox)\n",
    "        try:\n",
    "            newdata[boxslice] = newdata[boxslice] - model_\n",
    "        except TypeError:\n",
    "            print('Slicing operation failure',i,isource)\n",
    "    plt.imshow(newdata[0])\n",
    "    obs2 = scarlet2.Observation(jnp.asarray(newdata), jnp.asarray(obs.weights), psf=scarlet2.ArrayPSF(jnp.asarray(obs.frame.psf())),channels=obs.frame.channels)\n",
    "    obs2.match(model_frame_sc2)\n",
    "    obs_subtracted.append(obs2)\n",
    "obs_subtractedarr = np.asarray(obs_subtracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack to make a single gri observation\n",
    "multichannel = []\n",
    "multiimage=[]\n",
    "multivar=[]\n",
    "multipsf=[]\n",
    "for i in range(len(['g','i','r'])):\n",
    "    bind = np.argwhere(np.asarray(bandind)==i)[:,0]\n",
    "    if len(bind)==0:\n",
    "        continue\n",
    "    weights = np.asarray([obs.weights for obs in obs_subtractedarr[bind]])\n",
    "    weights[weights==0] = 1e-10\n",
    "    multivar.append(np.median(np.asarray([obs.weights for obs in obs_subtractedarr[bind]]),axis=0)*np.sqrt(len(obs_subtractedarr[bind])))\n",
    "    multiimage.append(np.average(np.asarray([obs.data for obs in obs_subtractedarr[bind]]),axis=0,weights=weights)[0])   \n",
    "    multipsf.append(np.mean(np.asarray([obs.frame.psf() for obs in obs_subtractedarr[bind]]),axis=0)[0])\n",
    "    channel_sc2 = bandall[i]   \n",
    "    multichannel.append(channel_sc2)\n",
    "\n",
    "obs_sc2 = scarlet2.Observation(jnp.asarray(multiimage), jnp.asarray(multivar),psf=scarlet2.ArrayPSF(jnp.asarray(multipsf)),channels=multichannel)#,wcs=w)\n",
    "model_frame_sc2 = scarlet2.Frame(scarlet2.Box((np.asarray(multiimage).shape[0],np.asarray(multiimage).shape[-1],np.asarray(multiimage).shape[-2])), psf=frame_psf_sc2, channels=multichannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = LinearPercentileNorm(obs.data[-1,10:-10,10:-10],percentiles=[0.01, 98])\n",
    "plt.figure(figsize=(4,4))\n",
    "scarlet2.plot.observation(obs_sc2,norm=norm,show_psf=True,add_labels=False)\n",
    "plt.savefig(plotdir+'/'+srcname+'_transientsubtractedimage.pdf')\n",
    "print('Saved',plotdir+'/'+srcname+'_transientsubtractedimage.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1bb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a model with a single non-parametric galaxy profile at the host galaxy position\n",
    "stepnum=500\n",
    "from galaxygrad import ZTF_ScoreNet32\n",
    "prior_model = ZTF_ScoreNet32\n",
    "with scarlet2.Scene(model_frame_sc2) as scene3:\n",
    "    for i,pos in enumerate(ra_dec[0]):      \n",
    "        coord = SkyCoord(pos[0],pos[1],unit=\"deg\")\n",
    "        pospix = np.asfarray(observations_sc2_init[0].frame.wcs.world_to_pixel(coord))\n",
    "        center = jnp.asarray(np.asfarray([pos[0],pos[1]]))\n",
    "        centerpix = jnp.asarray([pospix[1],pospix[0]])\n",
    "        \n",
    "        if i==indtransient:\n",
    "            flux = jnp.asarray(np.asarray(initialization.pixel_spectrum(observations_sc2, center))[:,0][inds0])\n",
    "            try:\n",
    "                morph_init = initialization.adaptive_gaussian_morph(observations_sc2[0], center) + 1e-6\n",
    "            except ValueError:\n",
    "                #continue\n",
    "                morph_init = observations_sc2[0].frame.psf()[0,:,:]-np.min(observations_sc2[0].frame.psf())\n",
    "                morph_init = morph_init/np.sum(morph_init)+1e-12\n",
    "           \n",
    "            morph_init = jnp.asarray(morph_init)\n",
    "            n_steps, peak_value = stepnum, 1\n",
    "           \n",
    "            schedule = optax.cosine_onecycle_schedule(n_steps, peak_value, final_div_factor=1)\n",
    "            morph_step = lambda p: scarlet2.relative_step(p, factor=1e-3)\n",
    "            test_step_morph =2e-3*peak_value\n",
    "            n_steps, peak_value2 = stepnum, jnp.max(flux[~np.isinf(flux)])\n",
    "            \n",
    "    \n",
    "            schedule2 = optax.cosine_onecycle_schedule(n_steps, peak_value2, final_div_factor=1)\n",
    "            gal_step = lambda p: scarlet2.relative_step(p, factor=5e-4)\n",
    "            test_step_gal =5e-3*peak_value2\n",
    "\n",
    "            scarlet2.Source(\n",
    "                centerpix,\n",
    "                scarlet2.StaticArraySpectrum(jnp.asarray(flux),filters=bandall),\n",
    "                scarlet2.ArrayMorphology(morph_init))\n",
    "            \n",
    "parameters = scene3.make_parameters()\n",
    "for i in range(len(scene3.sources)):\n",
    "        parameters += Parameter(scene3.sources[i].spectrum.data, name=f\"spectrum.{i}\", constraint=constraints.positive, stepsize=gal_step)\n",
    "        parameters += Parameter(scene3.sources[i].morphology.data, name=f\"morph.{i}\", constraint=constraints.positive, stepsize=morph_step)\n",
    "print(parameters)        \n",
    "scene.set_spectra_to_match(observations_sc2,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a75ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(\n",
    "    scene3,\n",
    "    observation=obs_sc2,\n",
    "    norm=normsingle[0],\n",
    "    channel_map=None,\n",
    "    show_model=False,\n",
    "    show_observed=True,\n",
    "    show_rendered=True,\n",
    "    show_residual=True,\n",
    "    add_labels=True,\n",
    "    add_boxes=True,\n",
    "    linear=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fae6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene3_ = scene3.fit(obs_sc2, parameters,max_iter=stepnum, e_rel=1e-6, schedule=schedule)\n",
    "model_ = obs_sc2.render(scene3_())\n",
    "scarlet2.plot.scene(\n",
    "    scene3_,\n",
    "    observation=obs_sc2,\n",
    "    norm=normsingle[0],\n",
    "    channel_map=None,\n",
    "    show_model=False,\n",
    "    show_observed=True,\n",
    "    show_rendered=True,\n",
    "    show_residual=True,\n",
    "    add_labels=True,\n",
    "    add_boxes=True,\n",
    "    linear=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(scene3_,\n",
    "                           norm=norm,\n",
    "                           observation=obs_sc2,\n",
    "                           show_rendered=False,\n",
    "                           show_observed=True,\n",
    "                           show_residual=True,\n",
    "                           add_labels=False,\n",
    "                          )\n",
    "plt.savefig(plotdir+'/'+srcname+'_hostmodel_withresidual.pdf')\n",
    "print('Saved',plotdir+'/'+srcname+'_hostmodel_withresidual.pdf')\n",
    "scarlet2.plot.scene(scene3_,\n",
    "                           norm=norm,\n",
    "                           observation=obs_sc2,\n",
    "                           show_rendered=False,\n",
    "                           show_observed=True,\n",
    "                           show_residual=False,\n",
    "                           add_labels=False,\n",
    "                          )\n",
    "plt.savefig(plotdir+'/'+srcname+'_hostmodel.pdf')\n",
    "print('Saved',plotdir+'/'+srcname+'_hostmodel.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a model with a single Sersic galaxy profile at the host galaxy position for centroid measurement\n",
    "stepnum=500\n",
    "from galaxygrad import ZTF_ScoreNet32\n",
    "prior_model = ZTF_ScoreNet32\n",
    "with scarlet2.Scene(model_frame_sc2) as scene3:\n",
    "    for i,pos in enumerate(ra_dec[0]):  \n",
    "        coord = SkyCoord(pos[0],pos[1],unit=\"deg\")\n",
    "        pospix = np.asarray(observations_sc2_init[0].frame.wcs.world_to_pixel(coord),dtype=int)\n",
    "        centerpix = jnp.asarray(np.asfarray([pospix[1],pospix[0]]))+1\n",
    "        center = centerpix\n",
    "        print(pos,'CENTER',center,centerpix)\n",
    "        if i==indtransient:\n",
    "            flux = jnp.asarray(np.asarray(initialization.pixel_spectrum(obs_sc2, center))+1e-6)\n",
    "            n_steps, peak_value = stepnum, 1#jnp.max(flux)\n",
    "            schedule = optax.cosine_onecycle_schedule(n_steps, peak_value, final_div_factor=1)\n",
    "            morph_step = lambda p: scarlet2.relative_step(p, factor=1e-3)#lambda p, it: scarlet2.relative_step(p, factor=2e-3) * schedule(it)\n",
    "            test_step_morph =2e-3*peak_value\n",
    "            n_steps, peak_value2 = stepnum, 0.1*jnp.max(flux[~np.isinf(flux)])\n",
    "            print('Making source')\n",
    "            schedule2 = optax.cosine_onecycle_schedule(n_steps, peak_value2, final_div_factor=1)\n",
    "            gal_step = lambda p: scarlet2.relative_step(p, factor=1e-3)\n",
    "            sersic = scarlet2.SersicMorphology(\n",
    "                                        center = jnp.asarray(np.asfarray(center)),\n",
    "                                        ellipticity = jnp.asarray([0.1,0.1]),        \n",
    "                                        size= jnp.asarray(3.0),\n",
    "                                        n=jnp.asarray(1.5),\n",
    "                        )\n",
    "            scarlet2.Source(\n",
    "                center,\n",
    "                scarlet2.ArraySpectrum(jnp.asarray(flux)) ,sersic)\n",
    "            \n",
    "parameters = scene3.make_parameters()\n",
    "\n",
    "for i in range(len(scene3.sources)):   \n",
    "    parameters += Parameter(scene3.sources[i].spectrum.data, name=f\"spectrum.{i}\", constraint=constraints.positive, stepsize=gal_step)\n",
    "    parameters += Parameter(scene3.sources[i].morphology.center, name=f\"morph.{i}\", constraint=constraints.positive, stepsize=pos_step)\n",
    "    parameters += Parameter(scene3.sources[i].morphology.ellipticity, name=f\"morph.{i}\", constraint=constraints.interval(0,1), stepsize=1e-3)\n",
    "    parameters += Parameter(scene3.sources[i].morphology.size, name=f\"morph.{i}\", constraint=constraints.interval(1.0,15), stepsize=5e-2)\n",
    "    parameters += Parameter(scene3.sources[i].morphology.n, name=f\"morph.{i}\", constraint=constraints.interval(.5,10), stepsize=1e-3) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(\n",
    "    scene3,\n",
    "    observation=obs_sc2,\n",
    "    norm=normsingle[0],\n",
    "    channel_map=None,\n",
    "    show_model=False,\n",
    "    show_observed=True,\n",
    "    show_rendered=True,\n",
    "    show_residual=True,\n",
    "    add_labels=True,\n",
    "    add_boxes=True,\n",
    "    linear=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea72205",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene3_ = scene3.fit(obs_sc2,parameters, max_iter=stepnum, e_rel=1e-6, schedule=schedule)\n",
    "print(scene3.sources[0].morphology.center)\n",
    "print(scene3_.sources[0].morphology.center)\n",
    "model_ = obs_sc2.render(scene3_())\n",
    "scarlet2.plot.scene(\n",
    "    scene3_,\n",
    "    observation=obs_sc2,\n",
    "    norm=normsingle[0],\n",
    "    channel_map=None,\n",
    "    show_model=False,\n",
    "    show_observed=True,\n",
    "    show_rendered=True,\n",
    "    show_residual=True,\n",
    "    add_labels=True,\n",
    "    add_boxes=True,\n",
    "    linear=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = scene3_.make_parameters()\n",
    "p = scene3_.sources[0].morphology.center\n",
    "prior = dist.Normal(p, scale=1)\n",
    "parameters += Parameter(p, name=f\"morphology.center:\"+str(0), prior=prior)\n",
    "p = scene3_.sources[0].morphology.ellipticity\n",
    "parameters += Parameter(p, name=f\"morphology.ellipticity:\"+str(0), prior=dist.Normal(p, scale=0.5))\n",
    "p = scene3_.sources[0].morphology.size\n",
    "parameters += Parameter(p, name=f\"morphology.size:\"+str(0), prior=dist.Normal(p, scale=1.0))\n",
    "p = scene3_.sources[0].morphology.n\n",
    "parameters += Parameter(p, name=f\"morphology.n:\"+str(0), prior=dist.Normal(p, scale=0.5))\n",
    "p = scene3_.sources[0].spectrum.data\n",
    "parameters += Parameter(p, name=f\"spectrum:\"+str(0), prior=dist.Normal(p, scale=1.0))\n",
    "\n",
    "\n",
    "mcmc = scene3_.sample(obs_sc2,parameters,num_warmup=600, num_samples=1300,dense_mass=True, init_strategy=init_to_sample) \n",
    "q = mcmc.get_samples()['morphology.center:'+str(0)] \n",
    "q1 = np.percentile(q,[2.5,16,50,84,97.5],axis=0) \n",
    "centergal = np.asfarray([q1[2,0],q1[2,1]])\n",
    "errorgal = np.asarray([np.abs(q1[4,0]-q1[0,0]),np.abs(q1[4,1]-q1[0,1])])\n",
    "corner.corner(mcmc).show() \n",
    "plt.savefig(plotdir+'/'+srcname+'_galcenter_corner.png')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "offset = np.linalg.norm(centergal - centerAGN)\n",
    "dx = centerAGN[0]-centergal[0]\n",
    "dy = centerAGN[1]-centergal[1]\n",
    "\n",
    "sigx = errorAGN[0]/centerAGN[0]+errorgal[0]/centergal[0]\n",
    "sigy = errorAGN[1]/centerAGN[1]+errorgal[1]/centergal[1]\n",
    "\n",
    "error = np.sqrt(1/offset**2*(dx**2*(errorAGN[0]**2+errorgal[0]**2)+dy**2*(errorAGN[1]**2+errorgal[1]**2)))\n",
    "errorpix = errorAGN+errorgal\n",
    "\n",
    "print('Offset',offset,error,errorpix)\n",
    "np.savetxt(plotdir+'/offset.txt',np.asarray([offset,error,centerAGN[0],centerAGN[1],centergal[0],centergal[1]],dtype=str),fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scarlet [~/.conda/envs/scarlet/]",
   "language": "python",
   "name": "conda_scarlet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
